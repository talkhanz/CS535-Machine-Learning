{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "project_phase2_tillGradient_Descnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install the required library.**"
      ],
      "metadata": {
        "id": "RI3-Xmuu5UNz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "!pip install python_speech_features"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.6/dist-packages (0.6)\n"
          ]
        }
      ],
      "metadata": {
        "id": "QnOFUUTn5bOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11c1e2e-5fb0-4827-b03e-3615f7344d35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the required libraries.**"
      ],
      "metadata": {
        "id": "Rj66P1f15cMo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "source": [
        "import python_speech_features as mfcc\n",
        "from scipy.io.wavfile import read\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "from collections import Counter\n",
        "gender_recognition_path = os.getcwd() + \"/Gender_Recognition\"\n",
        "speaker_recognition_path = os.getcwd() + \"/Speaker_Recognition\"\n",
        "gender_recognition_train_path = gender_recognition_path + \"/Train\"\n",
        "gender_recognition_test_path = gender_recognition_path + \"/Test\"\n",
        "speaker_train_costs_path = os.getcwd() + \"/speaker_train_costs.data\"\n",
        "speaker_val_costs_path = os.getcwd() + \"/speaker_val_costs.data\"\n",
        "\n",
        "gender_train_costs_path = os.getcwd() + \"/gender_train_costs.data\"\n",
        "gender_val_costs_path = os.getcwd() + \"/gender_val_costs.data\"\n",
        "\n",
        "gender_recognition_valid_path = gender_recognition_path + \"/Valid\"\n",
        "speaker_recognition_train_path = speaker_recognition_path + \"/Train\"\n",
        "speaker_recognition_test_path = speaker_recognition_path + \"/Test\"\n",
        "speaker_recognition_valid_path = speaker_recognition_path + \"/Valid\"\n",
        "\n",
        "train_speaker_thetas_path = os.getcwd() + \"/train_speaker_thetas.data\"\n",
        "train_gender_thetas_path = os.getcwd() + \"/train_gender_thetas.data\"\n",
        "\n",
        "train_X_gender_path = os.getcwd() + \"/train_X_gender.data\"\n",
        "train_X_speaker_path = os.getcwd() + \"/train_X_speaker.data\"\n",
        "\n",
        "train_Y_gender_path = os.getcwd() + \"/train_Y_gender.data\"\n",
        "train_Y_speaker_path = os.getcwd() + \"/train_Y_speaker.data\"\n",
        "\n",
        "\n",
        "X_val_gender_path = os.getcwd() + \"/X_val_gender.data\"\n",
        "X_val_speaker_path = os.getcwd() + \"/X_val_speaker.data\"\n",
        "\n",
        "Y_val_gender_path = os.getcwd() + \"/Y_val_gender.data\"\n",
        "Y_val_speaker_path = os.getcwd() + \"/Y_val_speaker.data\"\n",
        "\n",
        "test_X_gender_path = os.getcwd() + \"/test_X_gender.data\"\n",
        "test_X_speaker_path = os.getcwd() + \"/test_X_speaker.data\"\n",
        "\n",
        "test_Y_gender_path = os.getcwd() + \"/test_Y_gender.data\"\n",
        "test_Y_speaker_path = os.getcwd() + \"/test_Y_speaker.data\"\n",
        "\n",
        "train_speaker_labels_path  = os.getcwd() + \"/train_speaker_labels.data\"\n",
        "train_gender_labels_path  = os.getcwd() + \"/train_gender_labels.data\"\n",
        "\n",
        "test_speaker_labels_path =  os.getcwd() + \"/test_speaker_labels.data\"\n",
        "test_gender_labels_path  = os.getcwd() + \"/test_gender_labels.data\"\n",
        "\n",
        "train_speaker_counter_list_labels_path  = os.getcwd() + \"/train_speaker_counter_list_labels.data\"\n",
        "train_gender_counter_list_labels_path  = os.getcwd() + \"/train_gender_counter_list_labels.data\"\n",
        "\n",
        "test_speaker_counter_list_labels_path  = os.getcwd() + \"/test_speaker_counter_list_labels.data\"\n",
        "test_gender_counter_list_labels_path  = os.getcwd() + \"/test_gender_counter_list_labels.data\"\n",
        "\n",
        "val_speaker_counter_list_labels_path = os.getcwd() + \"/val_speaker_counter_list_labels.data\"\n",
        "val_gender_counter_list_labels_path = os.getcwd() + \"/val_gender_counter_list_labels.data\""
      ],
      "outputs": [],
      "metadata": {
        "id": "CbEfmo_H5exz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "def save_pickled_data(data,path):\n",
        "    with open(path,'wb' ,) as f:\n",
        "        pickle.dump(data,f)\n",
        "    print(\"pickled data saved as pickle dump at\",path)\n",
        "def load_pickled_data(path):\n",
        "    with open(path,'rb' ,) as f:\n",
        "        data = pickle.load(f)\n",
        "    # print(\"pickled data loaded as pickle dump from\",path)\n",
        "    return data\n",
        "def create_labels_counter_list(labels):\n",
        "  c = list(set(labels))\n",
        "  return c\n",
        "\n",
        "\n",
        "def get_MFCC(audio, sr):\n",
        "    features = mfcc.mfcc(audio, sr, 0.025, 0.01, 13, appendEnergy = True)\n",
        "    return np.mean(features, axis=0)\n",
        "\n",
        "def read_audio_files(dir_path,dataset_type):\n",
        "  audio_folders = [x[0] for x in os.walk(dir_path)]\n",
        "  all_audio_files = []\n",
        "  i = 0\n",
        "  labels = []\n",
        "  id = \"\"\n",
        "  for folder in audio_folders:\n",
        "    if i > 0:\n",
        "      audio_filenames = glob.glob(folder + \"/*.*\")\n",
        "      if dataset_type == \"speaker\":\n",
        "        id = folder.split(\"/\")[-1]\n",
        "        id = id.split(\"_\")[0]\n",
        "      if dataset_type == \"gender\":\n",
        "        id = folder.split(\"/\")[-1]\n",
        "        id = id.split(\"_\")[-1]\n",
        "\n",
        "      \n",
        "      for filename in audio_filenames:\n",
        "        sr,audio = read(filename)\n",
        "        all_audio_files.append([sr,audio])\n",
        "        labels.append(id)\n",
        "    i = i + 1\n",
        "  return all_audio_files,labels\n",
        "def feature_extraction(audio_files):\n",
        "  all_features = []\n",
        "  for i in range(len(audio_files)):\n",
        "    audio = audio_files[i][1]\n",
        "    sr = audio_files[i][0]\n",
        "    features = get_MFCC(audio,sr)\n",
        "    features = np.insert(features,0,1)\n",
        "    all_features.append(features)\n",
        "  return all_features\n",
        "def load_processed_data(data_path,dataset_type):\n",
        "  audio_files,labels = read_audio_files(data_path,dataset_type)\n",
        "  audio_features = feature_extraction(audio_files)\n",
        "  return audio_features,labels\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "XeN_8OUBe9Sx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_X_speaker,speaker_labels = load_processed_data(speaker_recognition_train_path,\"speaker\")\n",
        "train_X_gender,gender_labels = load_processed_data(gender_recognition_train_path,\"gender\")\n",
        "\n",
        "test_X_speaker,test_speaker_labels = load_processed_data(speaker_recognition_test_path,\"speaker\")\n",
        "test_X_gender,test_gender_labels = load_processed_data(gender_recognition_test_path,\"gender\")\n",
        "\n",
        "test_X_gender = np.array(test_X_gender)\n",
        "test_X_speaker = np.array(test_X_speaker)\n",
        "\n",
        "save_pickled_data(test_X_gender,test_X_gender_path)\n",
        "save_pickled_data(test_X_speaker,test_X_speaker_path )\n",
        "\n",
        "X_val_gender,val_gender_labels = load_processed_data(gender_recognition_valid_path,\"gender\")\n",
        "X_val_speaker,val_speaker_labels = load_processed_data(speaker_recognition_valid_path,\"speaker\")\n",
        "\n",
        "train_speaker_counter_list_labels = create_labels_counter_list(speaker_labels)\n",
        "train_gender_counter_list_labels = create_labels_counter_list(gender_labels)\n",
        "\n",
        "test_speaker_counter_list_labels = create_labels_counter_list(test_speaker_labels)\n",
        "test_gender_counter_list_labels = create_labels_counter_list(test_gender_labels)\n",
        "\n",
        "val_speaker_counter_list_labels = create_labels_counter_list(val_speaker_labels)\n",
        "val_gender_counter_list_labels = create_labels_counter_list(val_gender_labels)\n",
        "\n",
        "save_pickled_data(train_X_speaker,train_X_speaker_path)\n",
        "save_pickled_data(train_X_gender,train_X_gender_path)\n",
        "\n",
        "save_pickled_data(test_X_speaker,test_X_speaker_path)\n",
        "save_pickled_data(test_X_gender,test_X_gender_path)\n",
        "\n",
        "save_pickled_data(X_val_speaker,X_val_speaker_path)\n",
        "save_pickled_data(X_val_gender,X_val_gender_path)\n",
        "\n",
        "save_pickled_data(val_speaker_labels,Y_val_speaker_path)\n",
        "save_pickled_data(val_gender_labels,Y_val_gender_path)\n",
        "\n",
        "save_pickled_data(train_speaker_counter_list_labels,train_speaker_counter_list_labels_path )\n",
        "save_pickled_data(train_gender_counter_list_labels,train_gender_counter_list_labels_path )\n",
        "\n",
        "save_pickled_data(test_gender_counter_list_labels,test_gender_counter_list_labels_path )\n",
        "save_pickled_data(test_speaker_counter_list_labels,test_speaker_counter_list_labels_path )\n",
        "\n",
        "\n",
        "save_pickled_data(val_speaker_counter_list_labels,val_speaker_counter_list_labels_path )\n",
        "save_pickled_data(val_gender_counter_list_labels,val_gender_counter_list_labels_path )\n",
        "\n",
        "save_pickled_data(speaker_labels,train_speaker_labels_path)\n",
        "save_pickled_data(gender_labels,train_gender_labels_path)\n",
        "train_speaker_counter_list_labels = load_pickled_data(train_speaker_counter_list_labels_path )\n",
        "train_gender_counter_list_labels = load_pickled_data(train_gender_counter_list_labels_path )\n",
        "test_speaker_counter_list_labels = load_pickled_data(test_speaker_counter_list_labels_path )\n",
        "test_gender_counter_list_labels = load_pickled_data(test_gender_counter_list_labels_path )\n",
        "\n",
        "val_speaker_counter_list_labels = load_pickled_data(val_speaker_counter_list_labels_path )\n",
        "val_gender_counter_list_labels =  load_pickled_data(val_gender_counter_list_labels_path )\n",
        "Y_val_speaker = load_pickled_data(Y_val_speaker_path)\n",
        "Y_val_gender = load_pickled_data(Y_val_gender_path)\n",
        "test_Y_gender = create_labels_vector(test_gender_labels,dataset_type=\"test_gender\")\n",
        "test_Y_speaker = create_labels_vector(test_speaker_labels,dataset_type=\"test_speaker\")\n",
        "save_pickled_data(test_Y_speaker,test_Y_speaker_path)\n",
        "save_pickled_data(test_Y_gender,test_Y_gender_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pickled data saved as pickle dump at /content/test_X_gender.data\n",
            "pickled data saved as pickle dump at /content/test_X_speaker.data\n"
          ]
        }
      ],
      "metadata": {
        "id": "9zHCJkRR7NyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10f6020-9e8a-4f4a-b1c3-eb7ff18a92a1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "VBB8FNGKifQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aIh3DzuItpjx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "source": [
        "\n",
        "def execute_cross_validation(X,Y,thetas,epochs,alphas):\n",
        "  X = np.array(X)\n",
        "  Y = np.array(Y)\n",
        "  ce = []\n",
        "  all_costs = {}\n",
        "  best_costs = []\n",
        "  for alpha in alphas:\n",
        "    costs = []\n",
        "    for epoch in range(epochs):\n",
        "      thetas=gradientDescent(X,Y,thetas,alpha)\n",
        "      hx = h(X,thetas)  \n",
        "      for i,y in enumerate(Y):\n",
        "        l = cross_entropy(y,hx[i])\n",
        "        ce.append(l)\n",
        "      L = np.array(ce)\n",
        "      m = L.shape[0]\n",
        "      cost = computeCost(L,m)\n",
        "      costs.append(cost)\n",
        "    all_costs[alpha] = np.array(costs)\n",
        "    min_cost_index = np.argmin(costs)\n",
        "    best_costs.append(costs[min_cost_index])\n",
        "  best_costs = np.array(best_costs)\n",
        "  best_alpha_index = np.argmin(best_costs)\n",
        "  return alphas[best_alpha_index],all_costs\n",
        "\n",
        "def create_one_hot_encoding_vector(raw_labels):\n",
        "  one_hot_encoding = np.zeros(len(raw_labels))\n",
        "  return one_hot_encoding\n",
        "def encoding_index(label,label_type):\n",
        "  labels = []\n",
        "  if label_type == \"train_speaker\":\n",
        "    labels  = load_pickled_data(train_speaker_counter_list_labels_path)\n",
        "  if label_type == \"train_gender\":\n",
        "    labels  = load_pickled_data(train_gender_counter_list_labels_path)\n",
        "  if label_type == \"val_speaker\":\n",
        "    labels  = load_pickled_data(val_speaker_counter_list_labels_path)\n",
        "  if label_type == \"val_gender\":\n",
        "    labels  = load_pickled_data(val_gender_counter_list_labels_path)\n",
        "  if label_type == \"test_speaker\":\n",
        "    labels  = load_pickled_data(test_speaker_counter_list_labels_path)\n",
        "  if label_type == \"test_gender\":\n",
        "    labels  = load_pickled_data(test_gender_counter_list_labels_path)\n",
        "  index = labels.index(label)\n",
        "  return index\n",
        "def create_thetas(num_of_feature,num_of_classes):\n",
        "  thetas = np.zeros((num_of_feature,num_of_classes))\n",
        "  # thetas = np.random.normal(size=(num_of_feature*num_of_classes)).reshape((num_of_feature,num_of_classes))\n",
        " \n",
        "  return thetas\n",
        "\n",
        "def softmax(z):\n",
        "  exp_z = np.exp(z)\n",
        "  sum_exp_z = np.sum(exp_z)\n",
        "  s = exp_z/sum_exp_z\n",
        "  return s\n",
        "def cross_entropy(y,hx): \n",
        "  l = y*np.log(hx)\n",
        "  l = -np.sum(l)\n",
        "  return l\n",
        "\n",
        "def h(X,thetas):\n",
        "    hx = np.dot(X,thetas)\n",
        "    t = []\n",
        "    for x in hx:\n",
        "      s = softmax(x)\n",
        "      t.append(s) \n",
        "    return t\n",
        "def computeCost(L,m):\n",
        "  cost = np.sum(L)\n",
        "  cost = cost / m\n",
        "  return cost\n",
        "\n",
        "def gradientDescent(X,Y,thetas,alpha):\n",
        "  updates=np.zeros(thetas.shape)\n",
        "  preds=h(X,thetas)\n",
        "  feats=X.shape[1]\n",
        "  for s,sample in enumerate(X):\n",
        "    difference=Y[s]-preds[s]\n",
        "    for i,feat in enumerate(sample):\n",
        "      for j,diff in enumerate(difference):\n",
        "        updates[i][j]=updates[i][j]-(diff*feat)\n",
        "  updates=updates/X.shape[0]\n",
        "  thetas=thetas-alpha*updates\n",
        "  return thetas\n",
        "def create_labels_vector(Y,dataset_type,Y_val=None,val_dataset_type =None):\n",
        "  num_val = None\n",
        "  ytrue = []\n",
        "  if Y_val is not None:\n",
        "    num_val = len(Y_val)\n",
        "  \n",
        "  for i,y in enumerate(Y):\n",
        "    index = encoding_index(y,dataset_type)\n",
        "    if num_val is not None:\n",
        "      if i < num_val:\n",
        "        index_val = encoding_index(Y_val[i],val_dataset_type)\n",
        "    one_hot_vector = []\n",
        "    one_hot_vector_val = []\n",
        "    if dataset_type == \"train_speaker\":\n",
        "      one_hot_vector = create_one_hot_encoding_vector(train_speaker_counter_list_labels)\n",
        "      if num_val is not None:\n",
        "        if i < num_val:\n",
        "          one_hot_vector_val = create_one_hot_encoding_vector(val_speaker_counter_list_labels )\n",
        "    if dataset_type == \"train_gender\":\n",
        "      one_hot_vector = create_one_hot_encoding_vector(train_gender_counter_list_labels)\n",
        "      if num_val is not None:\n",
        "        if i < num_val:\n",
        "          one_hot_vector_val = create_one_hot_encoding_vector(val_gender_counter_list_labels )\n",
        "    if dataset_type == \"test_speaker\":\n",
        "      one_hot_vector = create_one_hot_encoding_vector(test_speaker_counter_list_labels)\n",
        "      if num_val is not None:\n",
        "        if i < num_val:\n",
        "          one_hot_vector_val = create_one_hot_encoding_vector(val_speaker_counter_list_labels )\n",
        "    if dataset_type == \"test_gender\":\n",
        "      one_hot_vector = create_one_hot_encoding_vector(test_gender_counter_list_labels)\n",
        "      if num_val is not None:\n",
        "        if i < num_val:\n",
        "          one_hot_vector_val = create_one_hot_encoding_vector(val_gender_counter_list_labels )\n",
        "    one_hot_vector[index] = 1\n",
        "    if num_val is not None:\n",
        "      if i < num_val:\n",
        "        one_hot_vector_val[index_val] = 1\n",
        "        yval.append(one_hot_vector_val)\n",
        "    ytrue.append(one_hot_vector)\n",
        "  Y = np.array(ytrue)\n",
        "  return Y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mnm_logistic_regression_train(X,Y,epochs =None,alphas=None,dataset_type=None):\n",
        "  #best epoch was found using \n",
        "  import datetime\n",
        "  print(\"starting training\")\n",
        "  start_time = datetime.datetime.now()\n",
        "  num_classes = len(list(set(Y)))\n",
        "  num_features = X.shape[1]\n",
        "  X_val = None\n",
        "  Y_val = None\n",
        "  if dataset_type == \"train_speaker\":\n",
        "    X_val = load_pickled_data(X_val_speaker_path)\n",
        "    Y_val = load_pickled_data(Y_val_speaker_path)\n",
        "    val_dataset_type = \"val_speaker\"\n",
        "    print(\"valsp loaded\")\n",
        "  if dataset_type == \"train_gender\":\n",
        "    X_val = load_pickled_data(X_val_gender_path)\n",
        "    Y_val = load_pickled_data(Y_val_gender_path)\n",
        "    val_dataset_type = \"val_gender\"\n",
        "    print(\"valgen loaded\")\n",
        "  thetas = create_thetas(num_features,num_classes)\n",
        "  hx = h(X,thetas)  \n",
        "  ytrue = []\n",
        "  yval = []\n",
        "  num_val = len(Y_val)\n",
        "  print(\"creating one hot encodings\")\n",
        "  for i,y in enumerate(Y):\n",
        "    index = encoding_index(y,dataset_type)\n",
        "    if i < num_val:\n",
        "      index_val = encoding_index(Y_val[i],val_dataset_type)\n",
        "    one_hot_vector = []\n",
        "    one_hot_vector_val = []\n",
        "    if dataset_type == \"train_speaker\":\n",
        "      one_hot_vector = create_one_hot_encoding_vector(train_speaker_counter_list_labels)\n",
        "      if i < num_val:\n",
        "        one_hot_vector_val = create_one_hot_encoding_vector(val_speaker_counter_list_labels )\n",
        "    if dataset_type == \"train_gender\":\n",
        "      one_hot_vector = create_one_hot_encoding_vector(train_gender_counter_list_labels)\n",
        "      if i < num_val:\n",
        "        one_hot_vector_val = create_one_hot_encoding_vector(val_gender_counter_list_labels )\n",
        "    one_hot_vector[index] = 1\n",
        "    if i < num_val:\n",
        "      one_hot_vector_val[index_val] = 1\n",
        "      yval.append(one_hot_vector_val)\n",
        "    ytrue.append(one_hot_vector)\n",
        "  Y = np.array(ytrue)\n",
        "  if dataset_type == \"train_gender\":\n",
        "    save_pickled_data(Y,train_Y_gender_path)\n",
        "  if dataset_type == \"train_speaker\":\n",
        "    save_pickled_data(Y,train_Y_speaker_path)\n",
        "  Y_val = np.array(yval)\n",
        "  print(\"created one hot encodings\")\n",
        "  ce = []\n",
        "  i = 0\n",
        "  train_costs = []\n",
        "  print(\"executing cross validation\")\n",
        "  best_alpha,val_costs = execute_cross_validation(X_val,Y_val,thetas,epochs,alphas)\n",
        "  if dataset_type==\"train_speaker\":\n",
        "    best_alpha = 0.1 # we ran it manually and it was better than cross validation\n",
        "  print(\"best alpha is\",best_alpha)\n",
        "  print(\"executing cross validation\")\n",
        "  print(\"starting training\")\n",
        "  costs = []\n",
        "  for epoch in range(epochs):\n",
        "    thetas=gradientDescent(X,Y,thetas,best_alpha)\n",
        "    hx = h(X,thetas)  \n",
        "    for i,y in enumerate(Y):\n",
        "      l = cross_entropy(y,hx[i])\n",
        "      ce.append(l)\n",
        "    L = np.array(ce)\n",
        "    m = L.shape[0]\n",
        "    cost = computeCost(L,m)\n",
        "    print(\"epoch:\",epoch , \"cost:\",cost)\n",
        "    train_costs.append(cost)\n",
        "  print(\"finished training training\")\n",
        "  if dataset_type == \"train_speaker\":\n",
        "    save_pickled_data(thetas,train_speaker_thetas_path)\n",
        "    save_pickled_data(train_costs,speaker_train_costs_path)\n",
        "    save_pickled_data(val_costs,speaker_val_costs_path)\n",
        "  if dataset_type == \"train_gender\":\n",
        "    save_pickled_data(thetas,train_gender_thetas_path)\n",
        "    save_pickled_data(train_costs,gender_train_costs_path)\n",
        "    save_pickled_data(val_costs,gender_val_costs_path)\n",
        "  preds  = h(X,thetas)\n",
        "  finish_time = datetime.datetime.now() - start_time\n",
        "  print(\"finished training in\" + str(finish_time))\n",
        "  return thetas,train_costs,val_costs\n",
        "\n",
        "train_X_gender = np.array(load_pickled_data(train_X_gender_path))\n",
        "train_X_speaker = np.array(load_pickled_data(train_X_speaker_path))\n",
        "gender_labels = load_pickled_data(train_gender_labels_path)\n",
        "speakers_labels = load_pickled_data(train_speaker_labels_path)\n",
        "\n",
        "gender_thetas,gender_train_costs,gender_val_costs = mnm_logistic_regression_train(train_X_gender,gender_labels,epochs = 200,alphas = [0.1,0.01,0.001,0.002],dataset_type=\"train_gender\")\n",
        "speaker_thetas,speaker_train_costs,speaker_val_costs = mnm_logistic_regression_train(train_X_speaker,speaker_labels,epochs = 200,alphas = [0.1,0.01,0.001,0.002],dataset_type=\"train_speaker\")\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting training\n",
            "valgen loaded\n",
            "creating one hot encodings\n",
            "pickled data saved as pickle dump at /content/train_Y_gender.data\n",
            "created one hot encodings\n",
            "executing cross validation\n",
            "best alpha is 0.002\n",
            "executing cross validation\n",
            "starting training\n",
            "epoch: 0 cost: 0.5704719725207362\n",
            "epoch: 1 cost: 0.5545940189880583\n",
            "epoch: 2 cost: 0.5431739354340378\n",
            "epoch: 3 cost: 0.5337769519041697\n",
            "epoch: 4 cost: 0.5255362995809778\n",
            "epoch: 5 cost: 0.5180769594328577\n",
            "epoch: 6 cost: 0.5112086680574761\n",
            "epoch: 7 cost: 0.5048207130715602\n",
            "epoch: 8 cost: 0.49884083636237575\n",
            "epoch: 9 cost: 0.49321740827481064\n",
            "epoch: 10 cost: 0.4879109610612886\n",
            "epoch: 11 cost: 0.4828898231534947\n",
            "epoch: 12 cost: 0.47812769109368947\n",
            "epoch: 13 cost: 0.47360218176278823\n",
            "epoch: 14 cost: 0.46929391261409564\n",
            "epoch: 15 cost: 0.4651858832204876\n",
            "epoch: 16 cost: 0.4612630382249874\n",
            "epoch: 17 cost: 0.45751194505608783\n",
            "epoch: 18 cost: 0.45392054764486905\n",
            "epoch: 19 cost: 0.4504779726163133\n",
            "epoch: 20 cost: 0.4471743730933034\n",
            "epoch: 21 cost: 0.4440008003672039\n",
            "epoch: 22 cost: 0.44094909681522104\n",
            "epoch: 23 cost: 0.4380118054192987\n",
            "epoch: 24 cost: 0.4351820925281303\n",
            "epoch: 25 cost: 0.4324536813679001\n",
            "epoch: 26 cost: 0.4298207944041743\n",
            "epoch: 27 cost: 0.4272781030807068\n",
            "epoch: 28 cost: 0.42482068376874355\n",
            "epoch: 29 cost: 0.4224439789893596\n",
            "epoch: 30 cost: 0.4201437631451869\n",
            "epoch: 31 cost: 0.41791611213231034\n",
            "epoch: 32 cost: 0.4157573763087541\n",
            "epoch: 33 cost: 0.4136641563802181\n",
            "epoch: 34 cost: 0.4116332818317176\n",
            "epoch: 35 cost: 0.40966179158927907\n",
            "epoch: 36 cost: 0.40774691664156265\n",
            "epoch: 37 cost: 0.40588606438926217\n",
            "epoch: 38 cost: 0.404076804521908\n",
            "epoch: 39 cost: 0.4023168562484543\n",
            "epoch: 40 cost: 0.4006040767306849\n",
            "epoch: 41 cost: 0.39893645058774596\n",
            "epoch: 42 cost: 0.39731208035659304\n",
            "epoch: 43 cost: 0.395729177807273\n",
            "epoch: 44 cost: 0.39418605602414114\n",
            "epoch: 45 cost: 0.39268112217463313\n",
            "epoch: 46 cost: 0.3912128708963352\n",
            "epoch: 47 cost: 0.3897798782410201\n",
            "epoch: 48 cost: 0.38838079612122867\n",
            "epoch: 49 cost: 0.3870143472110133\n",
            "epoch: 50 cost: 0.3856793202577485\n",
            "epoch: 51 cost: 0.38437456576655243\n",
            "epoch: 52 cost: 0.3830989920229469\n",
            "epoch: 53 cost: 0.38185156142298277\n",
            "epoch: 54 cost: 0.3806312870832317\n",
            "epoch: 55 cost: 0.3794372297058596\n",
            "epoch: 56 cost: 0.3782684946764849\n",
            "epoch: 57 cost: 0.3771242293747407\n",
            "epoch: 58 cost: 0.3760036206794217\n",
            "epoch: 59 cost: 0.3749058926518536\n",
            "epoch: 60 cost: 0.37383030438268056\n",
            "epoch: 61 cost: 0.37277614798866754\n",
            "epoch: 62 cost: 0.37174274674735786\n",
            "epoch: 63 cost: 0.3707294533585508\n",
            "epoch: 64 cost: 0.3697356483225642\n",
            "epoch: 65 cost: 0.36876073842615176\n",
            "epoch: 66 cost: 0.3678041553277541\n",
            "epoch: 67 cost: 0.36686535423449607\n",
            "epoch: 68 cost: 0.3659438126639996\n",
            "epoch: 69 cost: 0.3650390292846784\n",
            "epoch: 70 cost: 0.3641505228287179\n",
            "epoch: 71 cost: 0.3632778310724316\n",
            "epoch: 72 cost: 0.3624205098791254\n",
            "epoch: 73 cost: 0.36157813230000235\n",
            "epoch: 74 cost: 0.36075028772900475\n",
            "epoch: 75 cost: 0.35993658110781745\n",
            "epoch: 76 cost: 0.3591366321775619\n",
            "epoch: 77 cost: 0.3583500747739795\n",
            "epoch: 78 cost: 0.35757655616315637\n",
            "epoch: 79 cost: 0.35681573641506653\n",
            "epoch: 80 cost: 0.35606728781242125\n",
            "epoch: 81 cost: 0.35533089429250014\n",
            "epoch: 82 cost: 0.35460625091981596\n",
            "epoch: 83 cost: 0.3538930633876243\n",
            "epoch: 84 cost: 0.3531910475464335\n",
            "epoch: 85 cost: 0.3524999289578079\n",
            "epoch: 86 cost: 0.3518194424718781\n",
            "epoch: 87 cost: 0.35114933182708563\n",
            "epoch: 88 cost: 0.3504893492707964\n",
            "epoch: 89 cost: 0.3498392551995082\n",
            "epoch: 90 cost: 0.34919881781747125\n",
            "epoch: 91 cost: 0.348567812812619\n",
            "epoch: 92 cost: 0.3479460230487827\n",
            "epoch: 93 cost: 0.34733323827323254\n",
            "epoch: 94 cost: 0.3467292548386532\n",
            "epoch: 95 cost: 0.34613387543871954\n",
            "epoch: 96 cost: 0.3455469088564941\n",
            "epoch: 97 cost: 0.3449681697249193\n",
            "epoch: 98 cost: 0.3443974782987233\n",
            "epoch: 99 cost: 0.343834660237103\n",
            "epoch: 100 cost: 0.3432795463965879\n",
            "epoch: 101 cost: 0.34273197263352717\n",
            "epoch: 102 cost: 0.34219177961567415\n",
            "epoch: 103 cost: 0.3416588126423811\n",
            "epoch: 104 cost: 0.34113292147293967\n",
            "epoch: 105 cost: 0.340613960162637\n",
            "epoch: 106 cost: 0.3401017869061209\n",
            "epoch: 107 cost: 0.3395962638876911\n",
            "epoch: 108 cost: 0.33909725713815914\n",
            "epoch: 109 cost: 0.33860463639793853\n",
            "epoch: 110 cost: 0.33811827498604674\n",
            "epoch: 111 cost: 0.3376380496747211\n",
            "epoch: 112 cost: 0.3371638405693648\n",
            "epoch: 113 cost: 0.33669553099355964\n",
            "epoch: 114 cost: 0.33623300737889156\n",
            "epoch: 115 cost: 0.3357761591593568\n",
            "epoch: 116 cost: 0.33532487867012134\n",
            "epoch: 117 cost: 0.3348790610504256\n",
            "epoch: 118 cost: 0.33443860415043464\n",
            "epoch: 119 cost: 0.33400340844184556\n",
            "epoch: 120 cost: 0.3335733769320743\n",
            "epoch: 121 cost: 0.3331484150818538\n",
            "epoch: 122 cost: 0.33272843072608466\n",
            "epoch: 123 cost: 0.332313333997787\n",
            "epoch: 124 cost: 0.3319030372550112\n",
            "epoch: 125 cost: 0.3314974550105725\n",
            "epoch: 126 cost: 0.33109650386448136\n",
            "epoch: 127 cost: 0.3307001024389478\n",
            "epoch: 128 cost: 0.33030817131584495\n",
            "epoch: 129 cost: 0.32992063297652263\n",
            "epoch: 130 cost: 0.3295374117438668\n",
            "epoch: 131 cost: 0.3291584337265067\n",
            "epoch: 132 cost: 0.3287836267650768\n",
            "epoch: 133 cost: 0.3284129203804427\n",
            "epoch: 134 cost: 0.3280462457238098\n",
            "epoch: 135 cost: 0.32768353552863116\n",
            "epoch: 136 cost: 0.32732472406423996\n",
            "epoch: 137 cost: 0.32696974709113413\n",
            "epoch: 138 cost: 0.32661854181784306\n",
            "epoch: 139 cost: 0.32627104685931074\n",
            "epoch: 140 cost: 0.3259272021967337\n",
            "epoch: 141 cost: 0.3255869491387923\n",
            "epoch: 142 cost: 0.3252502302842204\n",
            "epoch: 143 cost: 0.3249169894856572\n",
            "epoch: 144 cost: 0.32458717181473157\n",
            "epoch: 145 cost: 0.3242607235283275\n",
            "epoch: 146 cost: 0.32393759203598566\n",
            "epoch: 147 cost: 0.3236177258683942\n",
            "epoch: 148 cost: 0.3233010746469276\n",
            "epoch: 149 cost: 0.32298758905419134\n",
            "epoch: 150 cost: 0.3226772208055342\n",
            "epoch: 151 cost: 0.3223699226214905\n",
            "epoch: 152 cost: 0.32206564820111616\n",
            "epoch: 153 cost: 0.3217643521961854\n",
            "epoch: 154 cost: 0.3214659901862144\n",
            "epoch: 155 cost: 0.3211705186542816\n",
            "epoch: 156 cost: 0.3208778949636142\n",
            "epoch: 157 cost: 0.3205880773349122\n",
            "epoch: 158 cost: 0.32030102482438366\n",
            "epoch: 159 cost: 0.3200166973024634\n",
            "epoch: 160 cost: 0.31973505543319153\n",
            "epoch: 161 cost: 0.3194560606542265\n",
            "epoch: 162 cost: 0.319179675157471\n",
            "epoch: 163 cost: 0.3189058618702873\n",
            "epoch: 164 cost: 0.31863458443728226\n",
            "epoch: 165 cost: 0.3183658072026401\n",
            "epoch: 166 cost: 0.3180994951929852\n",
            "epoch: 167 cost: 0.3178356141007547\n",
            "epoch: 168 cost: 0.3175741302680648\n",
            "epoch: 169 cost: 0.31731501067105106\n",
            "epoch: 170 cost: 0.31705822290466934\n",
            "epoch: 171 cost: 0.31680373516793847\n",
            "epoch: 172 cost: 0.31655151624961164\n",
            "epoch: 173 cost: 0.31630153551426105\n",
            "epoch: 174 cost: 0.31605376288876136\n",
            "epoch: 175 cost: 0.3158081688491599\n",
            "epoch: 176 cost: 0.31556472440791855\n",
            "epoch: 177 cost: 0.3153234011015171\n",
            "epoch: 178 cost: 0.315084170978404\n",
            "epoch: 179 cost: 0.3148470065872851\n",
            "epoch: 180 cost: 0.31461188096573695\n",
            "epoch: 181 cost: 0.31437876762913625\n",
            "epoch: 182 cost: 0.3141476405598936\n",
            "epoch: 183 cost: 0.31391847419698227\n",
            "epoch: 184 cost: 0.31369124342575244\n",
            "epoch: 185 cost: 0.313465923568022\n",
            "epoch: 186 cost: 0.31324249037243446\n",
            "epoch: 187 cost: 0.31302092000507575\n",
            "epoch: 188 cost: 0.31280118904034243\n",
            "epoch: 189 cost: 0.31258327445205186\n",
            "epoch: 190 cost: 0.31236715360478845\n",
            "epoch: 191 cost: 0.3121528042454776\n",
            "epoch: 192 cost: 0.31194020449517995\n",
            "epoch: 193 cost: 0.3117293328411008\n",
            "epoch: 194 cost: 0.31152016812880606\n",
            "epoch: 195 cost: 0.31131268955463975\n",
            "epoch: 196 cost: 0.3111068766583363\n",
            "epoch: 197 cost: 0.3109027093158223\n",
            "epoch: 198 cost: 0.31070016773220155\n",
            "epoch: 199 cost: 0.3104992324349174\n",
            "finished training training\n",
            "pickled data saved as pickle dump at /content/train_gender_thetas.data\n",
            "pickled data saved as pickle dump at /content/gender_train_costs.data\n",
            "pickled data saved as pickle dump at /content/gender_val_costs.data\n",
            "finished training in0:00:28.737728\n",
            "starting training\n",
            "valsp loaded\n",
            "creating one hot encodings\n",
            "pickled data saved as pickle dump at /content/train_Y_speaker.data\n",
            "created one hot encodings\n",
            "executing cross validation\n",
            "best alpha is 0.1\n",
            "executing cross validation\n",
            "starting training\n",
            "epoch: 0 cost: 4.630605437794454\n",
            "epoch: 1 cost: 4.490498776281582\n",
            "epoch: 2 cost: 4.3600786141147365\n",
            "epoch: 3 cost: 4.2381260196286\n",
            "epoch: 4 cost: 4.1237565153890765\n",
            "epoch: 5 cost: 4.0162334082641\n",
            "epoch: 6 cost: 3.9149218961255476\n",
            "epoch: 7 cost: 3.819272666909797\n",
            "epoch: 8 cost: 3.72880597488245\n",
            "epoch: 9 cost: 3.6430992057958793\n",
            "epoch: 10 cost: 3.5617774510717464\n",
            "epoch: 11 cost: 3.484505998166582\n",
            "epoch: 12 cost: 3.4109843044405057\n",
            "epoch: 13 cost: 3.3409411897238925\n",
            "epoch: 14 cost: 3.2741309912161767\n",
            "epoch: 15 cost: 3.2103304511706043\n",
            "epoch: 16 cost: 3.1493361528659336\n",
            "epoch: 17 cost: 3.0909623664216626\n",
            "epoch: 18 cost: 3.0350392051795385\n",
            "epoch: 19 cost: 2.981411023375018\n",
            "epoch: 20 cost: 2.9299350072000685\n",
            "epoch: 21 cost: 2.8804799258488862\n",
            "epoch: 22 cost: 2.8329250186302484\n",
            "epoch: 23 cost: 2.7871590003049214\n",
            "epoch: 24 cost: 2.743079170646922\n",
            "epoch: 25 cost: 2.7005906166708824\n",
            "epoch: 26 cost: 2.659605497581173\n",
            "epoch: 27 cost: 2.6200424036459453\n",
            "epoch: 28 cost: 2.5818257810991394\n",
            "epoch: 29 cost: 2.544885415945602\n",
            "epoch: 30 cost: 2.5091559702464967\n",
            "epoch: 31 cost: 2.4745765651168545\n",
            "epoch: 32 cost: 2.4410904052792772\n",
            "epoch: 33 cost: 2.4086444405855696\n",
            "epoch: 34 cost: 2.3771890604381682\n",
            "epoch: 35 cost: 2.346677817513808\n",
            "epoch: 36 cost: 2.3170671776130365\n",
            "epoch: 37 cost: 2.2883162928329113\n",
            "epoch: 38 cost: 2.26038679558983\n",
            "epoch: 39 cost: 2.233242611308891\n",
            "epoch: 40 cost: 2.206849787849774\n",
            "epoch: 41 cost: 2.181176339961139\n",
            "epoch: 42 cost: 2.1561921072497583\n",
            "epoch: 43 cost: 2.1318686243207714\n",
            "epoch: 44 cost: 2.108179001894632\n",
            "epoch: 45 cost: 2.085097817837298\n",
            "epoch: 46 cost: 2.062601017155419\n",
            "epoch: 47 cost: 2.040665820109741\n",
            "epoch: 48 cost: 2.0192706376894813\n",
            "epoch: 49 cost: 1.9983949937695262\n",
            "epoch: 50 cost: 1.9780194533423245\n",
            "epoch: 51 cost: 1.9581255562784012\n",
            "epoch: 52 cost: 1.9386957561244988\n",
            "epoch: 53 cost: 1.9197133634973222\n",
            "epoch: 54 cost: 1.901162493674424\n",
            "epoch: 55 cost: 1.8830280180226235\n",
            "epoch: 56 cost: 1.8652955189389964\n",
            "epoch: 57 cost: 1.8479512480104567\n",
            "epoch: 58 cost: 1.8309820871256457\n",
            "epoch: 59 cost: 1.8143755122976786\n",
            "epoch: 60 cost: 1.7981195599785527\n",
            "epoch: 61 cost: 1.782202795666014\n",
            "epoch: 62 cost: 1.7666142846216644\n",
            "epoch: 63 cost: 1.751343564535254\n",
            "epoch: 64 cost: 1.7363806199847116\n",
            "epoch: 65 cost: 1.7217158585545917\n",
            "epoch: 66 cost: 1.7073400884875345\n",
            "epoch: 67 cost: 1.6932444977540528\n",
            "epoch: 68 cost: 1.6794206344357054\n",
            "epoch: 69 cost: 1.6658603883255203\n",
            "epoch: 70 cost: 1.6525559736575302\n",
            "epoch: 71 cost: 1.6394999128845318\n",
            "epoch: 72 cost: 1.6266850214297865\n",
            "epoch: 73 cost: 1.6141043933443648\n",
            "epoch: 74 cost: 1.601751387807303\n",
            "epoch: 75 cost: 1.5896196164107126\n",
            "epoch: 76 cost: 1.5777029311765167\n",
            "epoch: 77 cost: 1.5659954132556289\n",
            "epoch: 78 cost: 1.5544913622641658\n",
            "epoch: 79 cost: 1.5431852862147457\n",
            "epoch: 80 cost: 1.5320718920040792\n",
            "epoch: 81 cost: 1.5211460764209597\n",
            "epoch: 82 cost: 1.5104029176414056\n",
            "epoch: 83 cost: 1.4998376671801477\n",
            "epoch: 84 cost: 1.4894457422698733\n",
            "epoch: 85 cost: 1.4792227186417057\n",
            "epoch: 86 cost: 1.4691643236822671\n",
            "epoch: 87 cost: 1.4592664299444165\n",
            "epoch: 88 cost: 1.4495250489903462\n",
            "epoch: 89 cost: 1.4399363255471926\n",
            "epoch: 90 cost: 1.430496531956675\n",
            "epoch: 91 cost: 1.4212020629015232\n",
            "epoch: 92 cost: 1.412049430392619\n",
            "epoch: 93 cost: 1.403035259001837\n",
            "epoch: 94 cost: 1.3941562813265629\n",
            "epoch: 95 cost: 1.385409333672786\n",
            "epoch: 96 cost: 1.3767913519444999\n",
            "epoch: 97 cost: 1.3682993677279458\n",
            "epoch: 98 cost: 1.3599305045599466\n",
            "epoch: 99 cost: 1.351681974370269\n",
            "epoch: 100 cost: 1.3435510740885739\n",
            "epoch: 101 cost: 1.3355351824070985\n",
            "epoch: 102 cost: 1.327631756690762\n",
            "epoch: 103 cost: 1.3198383300268905\n",
            "epoch: 104 cost: 1.3121525084072236\n",
            "epoch: 105 cost: 1.3045719680353152\n",
            "epoch: 106 cost: 1.2970944527528372\n",
            "epoch: 107 cost: 1.2897177715786923\n",
            "epoch: 108 cost: 1.2824397963551817\n",
            "epoch: 109 cost: 1.2752584594958238\n",
            "epoch: 110 cost: 1.2681717518297193\n",
            "epoch: 111 cost: 1.2611777205376553\n",
            "epoch: 112 cost: 1.2542744671754158\n",
            "epoch: 113 cost: 1.2474601457800119\n",
            "epoch: 114 cost: 1.2407329610547981\n",
            "epoch: 115 cost: 1.2340911666296515\n",
            "epoch: 116 cost: 1.2275330633926114\n",
            "epoch: 117 cost: 1.221056997889569\n",
            "epoch: 118 cost: 1.2146613607887813\n",
            "epoch: 119 cost: 1.2083445854071626\n",
            "epoch: 120 cost: 1.202105146295461\n",
            "epoch: 121 cost: 1.1959415578795933\n",
            "epoch: 122 cost: 1.189852373155544\n",
            "epoch: 123 cost: 1.183836182435376\n",
            "epoch: 124 cost: 1.1778916121420322\n",
            "epoch: 125 cost: 1.1720173236507143\n",
            "epoch: 126 cost: 1.1662120121747575\n",
            "epoch: 127 cost: 1.1604744056940064\n",
            "epoch: 128 cost: 1.1548032639238168\n",
            "epoch: 129 cost: 1.1491973773228874\n",
            "epoch: 130 cost: 1.143655566138226\n",
            "epoch: 131 cost: 1.1381766794856352\n",
            "epoch: 132 cost: 1.1327595944641804\n",
            "epoch: 133 cost: 1.127403215303183\n",
            "epoch: 134 cost: 1.1221064725403493\n",
            "epoch: 135 cost: 1.1168683222297164\n",
            "epoch: 136 cost: 1.1116877451781535\n",
            "epoch: 137 cost: 1.1065637462092284\n",
            "epoch: 138 cost: 1.1014953534532943\n",
            "epoch: 139 cost: 1.0964816176627132\n",
            "epoch: 140 cost: 1.0915216115511819\n",
            "epoch: 141 cost: 1.086614429156173\n",
            "epoch: 142 cost: 1.0817591852235544\n",
            "epoch: 143 cost: 1.0769550146134828\n",
            "epoch: 144 cost: 1.0722010717267279\n",
            "epoch: 145 cost: 1.067496529950598\n",
            "epoch: 146 cost: 1.0628405811236976\n",
            "epoch: 147 cost: 1.0582324350187677\n",
            "epoch: 148 cost: 1.0536713188429034\n",
            "epoch: 149 cost: 1.049156476754461\n",
            "epoch: 150 cost: 1.0446871693960185\n",
            "epoch: 151 cost: 1.040262673442759\n",
            "epoch: 152 cost: 1.0358822811656907\n",
            "epoch: 153 cost: 1.0315453000091326\n",
            "epoch: 154 cost: 1.027251052181929\n",
            "epoch: 155 cost: 1.0229988742618683\n",
            "epoch: 156 cost: 1.0187881168128146\n",
            "epoch: 157 cost: 1.0146181440140751\n",
            "epoch: 158 cost: 1.0104883333015469\n",
            "epoch: 159 cost: 1.0063980750202115\n",
            "epoch: 160 cost: 1.0023467720875552\n",
            "epoch: 161 cost: 0.998333839667521\n",
            "epoch: 162 cost: 0.9943587048546019\n",
            "epoch: 163 cost: 0.9904208063677163\n",
            "epoch: 164 cost: 0.9865195942535055\n",
            "epoch: 165 cost: 0.9826545295987231\n",
            "epoch: 166 cost: 0.9788250842513851\n",
            "epoch: 167 cost: 0.9750307405503776\n",
            "epoch: 168 cost: 0.971270991063216\n",
            "epoch: 169 cost: 0.9675453383316759\n",
            "epoch: 170 cost: 0.9638532946250179\n",
            "epoch: 171 cost: 0.9601943817005425\n",
            "epoch: 172 cost: 0.9565681305712223\n",
            "epoch: 173 cost: 0.9529740812801678\n",
            "epoch: 174 cost: 0.9494117826816937\n",
            "epoch: 175 cost: 0.9458807922287591\n",
            "epoch: 176 cost: 0.9423806757665668\n",
            "epoch: 177 cost: 0.9389110073321156\n",
            "epoch: 178 cost: 0.9354713689595009\n",
            "epoch: 179 cost: 0.9320613504907781\n",
            "epoch: 180 cost: 0.9286805493921977\n",
            "epoch: 181 cost: 0.9253285705756388\n",
            "epoch: 182 cost: 0.922005026225068\n",
            "epoch: 183 cost: 0.9187095356278597\n",
            "epoch: 184 cost: 0.9154417250108174\n",
            "epoch: 185 cost: 0.9122012273807463\n",
            "epoch: 186 cost: 0.9089876823694277\n",
            "epoch: 187 cost: 0.9058007360828565\n",
            "epoch: 188 cost: 0.9026400409546008\n",
            "epoch: 189 cost: 0.8995052556031565\n",
            "epoch: 190 cost: 0.896396044693169\n",
            "epoch: 191 cost: 0.8933120788003983\n",
            "epoch: 192 cost: 0.8902530342803127\n",
            "epoch: 193 cost: 0.8872185931401934\n",
            "epoch: 194 cost: 0.8842084429146464\n",
            "epoch: 195 cost: 0.8812222765444107\n",
            "epoch: 196 cost: 0.8782597922583635\n",
            "epoch: 197 cost: 0.8753206934586247\n",
            "epoch: 198 cost: 0.8724046886086636\n",
            "epoch: 199 cost: 0.8695114911243202\n",
            "finished training training\n",
            "pickled data saved as pickle dump at /content/train_speaker_thetas.data\n",
            "pickled data saved as pickle dump at /content/speaker_train_costs.data\n",
            "pickled data saved as pickle dump at /content/speaker_val_costs.data\n",
            "finished training in0:13:18.278470\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIWQN88hCoV7",
        "outputId": "74f98154-2268-482c-9344-9effb0b10a34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "source": [
        "def compute_accuracy(predictions,ground_truth,dataset_type= None):\n",
        "  accuracy = 0\n",
        "  if dataset_type == \"gender\":\n",
        "      total = len(predictions) \n",
        "      l = len(predictions)\n",
        "      match = 0\n",
        "      for i in range(l):\n",
        "          if np.argmax(predictions[i]) == np.argmax(ground_truth[i]):\n",
        "              match = match + 1\n",
        "      accuracy = match / total\n",
        "  if dataset_type == \"speaker\":\n",
        "      accuracy =  0\n",
        "  return accuracy\n",
        "def compute_interclass_false_positives(predictions,ground_truth,dataset_type=None):\n",
        "  if dataset_type == \"gender\":\n",
        "      l = len(predictions)\n",
        "      total = l\n",
        "      neg_false_pos = 0\n",
        "      pos_false_pos =  0\n",
        "      for i in range(l):\n",
        "          if np.argmax(predictions[i]) == 0 and np.argmax(ground_truth[i]) == 1:\n",
        "              neg_false_pos = neg_false_pos + 1\n",
        "          if np.argmax(predictions[i]) == 1 and np.argmax(ground_truth[i])  == 0:\n",
        "              pos_false_pos =  pos_false_pos + 1\n",
        "      all_fps = [pos_false_pos,neg_false_pos]\n",
        "      return all_fps\n",
        "def compute_true_positives(predictions,ground_truth,dataset_type=None):\n",
        "    if dataset_type == \"gender\":\n",
        "      l = len(predictions)\n",
        "      total = l\n",
        "      neg_match = 0\n",
        "      pos_match =  0\n",
        "      for i in range(l):\n",
        "          if np.argmax(predictions[i]) == np.argmax(ground_truth[i]) and np.argmax(ground_truth[i]) == 0:\n",
        "              neg_match = neg_match + 1\n",
        "          if np.argmax(predictions[i]) == np.argmax(ground_truth[i]) and np.argmax(ground_truth[i]) == 1:\n",
        "              pos_match = pos_match + 1\n",
        "      all_tps = [neg_match,pos_match ]\n",
        "      return  all_tps\n",
        "def compute_confusion_matrix(predictions,ground_truth,dataset_type=None):\n",
        "    if dataset_type == \"gender\":\n",
        "      all_tps = compute_true_positives(predictions,ground_truth,dataset_type=dataset_type)\n",
        "      all_fps = compute_interclass_false_positives(predictions,ground_truth,dataset_type=dataset_type)\n",
        "      tp_neg = all_tps[0]\n",
        "      tp_pos = all_tps[1]\n",
        "      matrix = [[2,3],[5,6]]\n",
        "      matrix[0][0] = tp_neg\n",
        "      matrix[0][1] = all_fps[1]\n",
        "      matrix[1][0] =all_fps[0]\n",
        "      matrix[1][1] =tp_pos\n",
        "      return matrix\n",
        "def make_predictions(thetas,X):\n",
        "  preds = h(X,thetas)\n",
        "  return preds"
      ],
      "outputs": [],
      "metadata": {
        "id": "9GsjyF1QKO5m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "source": [
        "test_X_gender = load_pickled_data(test_X_gender_path)\n",
        "gender_preds = make_predictions(gender_thetas,test_X_gender)\n",
        "test_Y_gender = load_pickled_data(test_Y_gender_path)\n",
        "thetas1=load_pickled_data(\"/content/train_speaker_thetas.data\")\n",
        "test_X=load_pickled_data(\"/content/test_X_speaker.data\")\n",
        "preds=h(test_X_speaker,thetas)\n",
        "\n",
        "pred_labels=[np.argmax(i) for i in preds]\n",
        "ground_truths=[np.argmax(i) for i in test_Y_speaker]\n",
        "\n",
        "pred_labels_gender=[np.argmax(i) for i in gender_preds]\n",
        "ground_truths_gender=[np.argmax(i) for i in test_Y_gender]\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"-------------- speaker recognitoin accuracy part ---------\")\n",
        "print(accuracy_score(ground_truths,pred_labels))\n",
        "print(classification_report(ground_truths,pred_labels))\n",
        "print(confusion_matrix(ground_truths,pred_labels))\n",
        "\n",
        "print(\"-------------- gender recognitoin accuracy part ---------\")\n",
        "print(accuracy_score(ground_truths_gender,pred_labels_gender))\n",
        "print(classification_report(ground_truths_gender,pred_labels_gender))\n",
        "print(confusion_matrix(ground_truths_gender,pred_labels_gender))\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "smBvEDz1TFHZ",
        "outputId": "8cb1700b-2a33-4249-8189-065e17fca850"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(train_costs_gender)\n",
        "plt.title(\"Training loss for gender\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.show()\n",
        "plt.plot(val_costs_gender)\n",
        "plt.title(\"Validation loss for gender\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ha4gPLd2aCJC"
      }
    }
  ]
}
